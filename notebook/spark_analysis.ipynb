{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5979457a",
   "metadata": {},
   "source": [
    "# Spark Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc117424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum as spark_sum, avg, count, desc, when\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d8e43e",
   "metadata": {},
   "source": [
    "## spark setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b22943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Spark Session created successfully\n",
      "Spark Version: 3.5.3\n",
      "Master: spark://spark-master:7077\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"StockPortfolioAnalysis\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"✅ Spark Session created successfully\")\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(f\"Master: {spark.sparkContext.master}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154c617d",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9160ee40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded successfully\n",
      "Total rows: 10000\n",
      "Total columns: 16\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\n",
    "    \"/home/jovyan/output/FULL_STOCKS.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "print(f\"✅ Data loaded successfully\")\n",
    "print(f\"Total rows: {df.count()}\")\n",
    "print(f\"Total columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bfaa81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FIRST 10 RECORDS\n",
      "================================================================================\n",
      "+--------------+----------+-----------+------------+----------------+--------+------------------+------------------+------------------+---------------------+--------+----------+----------+--------------------+------------+--------------+\n",
      "|transaction_id|timestamp |customer_id|stock_ticker|transaction_type|quantity|average_trade_size|stock_price       |total_trade_amount|customer_account_type|day_name|is_weekend|is_holiday|stock_liquidity_tier|stock_sector|stock_industry|\n",
      "+--------------+----------+-----------+------------+----------------+--------+------------------+------------------+------------------+---------------------+--------+----------+----------+--------------------+------------+--------------+\n",
      "|6253          |2024-03-14|1006       |5           |0               |477     |267.17625         |71.65242981011856 |34178.209019426555|1                    |2       |0         |0         |High                |1           |2             |\n",
      "|4685          |2023-12-04|4955       |5           |1               |137     |207.79            |94.43958142789144 |12938.222655621128|1                    |1       |0         |0         |High                |1           |2             |\n",
      "|1732          |2023-05-04|696        |11          |0               |155     |155.0             |20.69213814906549 |3207.281413105151 |1                    |2       |0         |0         |High                |4           |1             |\n",
      "|4743          |2023-12-06|4955       |12          |1               |12      |208.4             |128.35260245942936|1540.2312295131524|1                    |4       |0         |0         |Mid                 |1           |7             |\n",
      "|4522          |2023-11-22|1816       |17          |1               |91      |173.12            |232.5033292857061 |21157.802964999253|1                    |4       |0         |0         |Mid                 |4           |6             |\n",
      "|6341          |2024-03-20|1899       |8           |0               |1509    |267.17625         |453.0888018696642 |683711.0020213233 |1                    |4       |0         |0         |High                |4           |1             |\n",
      "|577           |2023-02-08|3588       |4           |0               |106     |169.53            |188.04131337039905|19932.3792172623  |1                    |4       |0         |0         |Low                 |1           |4             |\n",
      "|5203          |2024-01-03|1513       |9           |1               |372     |179.31            |169.25554709012007|62963.06351752466 |1                    |4       |0         |0         |High                |0           |5             |\n",
      "|6364          |2024-03-21|3588       |18          |0               |79      |178.61            |51.01282731782194 |4030.013358107933 |1                    |2       |0         |0         |Mid                 |1           |2             |\n",
      "|440           |2023-01-30|182        |8           |0               |19      |267.17625         |232.72566137599807|4421.787566143963 |1                    |1       |0         |1         |High                |4           |1             |\n",
      "+--------------+----------+-----------+------------+----------------+--------+------------------+------------------+------------------+---------------------+--------+----------+----------+--------------------+------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "DataFrame Schema:\n",
      "root\n",
      " |-- transaction_id: integer (nullable = true)\n",
      " |-- timestamp: date (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- stock_ticker: integer (nullable = true)\n",
      " |-- transaction_type: integer (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- average_trade_size: double (nullable = true)\n",
      " |-- stock_price: double (nullable = true)\n",
      " |-- total_trade_amount: double (nullable = true)\n",
      " |-- customer_account_type: integer (nullable = true)\n",
      " |-- day_name: integer (nullable = true)\n",
      " |-- is_weekend: integer (nullable = true)\n",
      " |-- is_holiday: integer (nullable = true)\n",
      " |-- stock_liquidity_tier: string (nullable = true)\n",
      " |-- stock_sector: integer (nullable = true)\n",
      " |-- stock_industry: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FIRST 10 RECORDS\")\n",
    "print(\"=\"*80)\n",
    "df.show(10, truncate=False)\n",
    "\n",
    "print(\"\\nDataFrame Schema:\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc3b011",
   "metadata": {},
   "source": [
    "-----------\n",
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4f5219",
   "metadata": {},
   "source": [
    "### Q1. Total Trading Volume by Stock Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc87547e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Q1: Total Trading Volume for Each Stock Ticker\n",
      "================================================================================\n",
      "+------------+------------+\n",
      "|stock_ticker|total_volume|\n",
      "+------------+------------+\n",
      "|5           |611667      |\n",
      "|11          |428057      |\n",
      "|8           |314915      |\n",
      "|17          |153811      |\n",
      "|12          |152604      |\n",
      "|9           |125862      |\n",
      "|7           |104680      |\n",
      "|19          |49724       |\n",
      "|16          |35435       |\n",
      "|18          |34229       |\n",
      "|10          |32119       |\n",
      "|6           |28486       |\n",
      "|2           |8570        |\n",
      "|4           |6997        |\n",
      "|1           |4405        |\n",
      "|0           |3557        |\n",
      "|14          |3302        |\n",
      "|15          |3210        |\n",
      "|3           |2857        |\n",
      "|13          |1512        |\n",
      "+------------+------------+\n",
      "\n",
      "✅ Q1 completed and saved\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Q1: Total Trading Volume for Each Stock Ticker\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "q1_result = df.groupBy(\"stock_ticker\") \\\n",
    "    .agg(spark_sum(\"quantity\").alias(\"total_volume\")) \\\n",
    "    .orderBy(desc(\"total_volume\"))\n",
    "\n",
    "q1_result.show(20, truncate=False)\n",
    "\n",
    "# Save results\n",
    "q1_result.coalesce(1).write.mode(\"overwrite\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"output/spark_results/q1_volume_by_ticker\")\n",
    "\n",
    "print(\"✅ Q1 completed and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fe836c",
   "metadata": {},
   "source": [
    "### Q2. verage Stock Price by Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dce39a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Q2: Average Stock Price by Sector\n",
      "================================================================================\n",
      "+------------+------------------+\n",
      "|stock_sector|average_price     |\n",
      "+------------+------------------+\n",
      "|0           |213.6248469077013 |\n",
      "|4           |153.67922533016082|\n",
      "|3           |152.00790316478043|\n",
      "|1           |101.49595512796058|\n",
      "|2           |79.92351314619137 |\n",
      "+------------+------------------+\n",
      "\n",
      "✅ Q2 completed and saved\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Q2: Average Stock Price by Sector\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "q2_result = df.groupBy(\"stock_sector\") \\\n",
    "    .agg(avg(\"stock_price\").alias(\"average_price\")) \\\n",
    "    .orderBy(desc(\"average_price\"))\n",
    "\n",
    "q2_result.show(truncate=False)\n",
    "\n",
    "# Save results\n",
    "q2_result.coalesce(1).write.mode(\"overwrite\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"output/spark_results/q2_avg_price_by_sector\")\n",
    "\n",
    "print(\"✅ Q2 completed and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2df3276",
   "metadata": {},
   "source": [
    "### Q3. Weekend Transactions (Buy vs Sell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a669dc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Q3: Buy vs Sell Transactions on Weekends\n",
      "================================================================================\n",
      "+----------------+-----------------+\n",
      "|transaction_type|transaction_count|\n",
      "+----------------+-----------------+\n",
      "+----------------+-----------------+\n",
      "\n",
      "\n",
      "Total weekend transactions: 0\n",
      "✅ Q3 completed and saved\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Q3: Buy vs Sell Transactions on Weekends\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Filter for weekend transactions\n",
    "weekend_df = df.filter(col(\"is_weekend\") == 1)\n",
    "\n",
    "q3_result = weekend_df.groupBy(\"transaction_type\") \\\n",
    "    .agg(count(\"transaction_id\").alias(\"transaction_count\")) \\\n",
    "    .orderBy(desc(\"transaction_count\"))\n",
    "\n",
    "q3_result.show(truncate=False)\n",
    "\n",
    "total_weekend = weekend_df.count()\n",
    "print(f\"\\nTotal weekend transactions: {total_weekend}\")\n",
    "\n",
    "# Save results\n",
    "q3_result.coalesce(1).write.mode(\"overwrite\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"output/spark_results/q3_weekend_transactions\")\n",
    "\n",
    "print(\"✅ Q3 completed and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7484ebc5",
   "metadata": {},
   "source": [
    "### Q4. Customers with More Than 10 Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ddd8029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Q4: Customers with More Than 10 Transactions\n",
      "================================================================================\n",
      "Total customers with >10 transactions: 74\n",
      "\n",
      "Top 20 customers:\n",
      "+-----------+-----------------+\n",
      "|customer_id|transaction_count|\n",
      "+-----------+-----------------+\n",
      "|4747       |1826             |\n",
      "|4955       |897              |\n",
      "|3588       |611              |\n",
      "|3938       |444              |\n",
      "|193        |419              |\n",
      "|1513       |417              |\n",
      "|4519       |284              |\n",
      "|1157       |227              |\n",
      "|845        |209              |\n",
      "|4023       |189              |\n",
      "|182        |162              |\n",
      "|2426       |113              |\n",
      "|227        |102              |\n",
      "|1816       |86               |\n",
      "|3339       |82               |\n",
      "|1185       |73               |\n",
      "|4700       |63               |\n",
      "|474        |61               |\n",
      "|3163       |47               |\n",
      "|1494       |45               |\n",
      "+-----------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "✅ Q4 completed and saved\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Q4: Customers with More Than 10 Transactions\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "q4_result = df.groupBy(\"customer_id\") \\\n",
    "    .agg(count(\"transaction_id\").alias(\"transaction_count\")) \\\n",
    "    .filter(col(\"transaction_count\") > 10) \\\n",
    "    .orderBy(desc(\"transaction_count\"))\n",
    "\n",
    "print(f\"Total customers with >10 transactions: {q4_result.count()}\")\n",
    "print(\"\\nTop 20 customers:\")\n",
    "q4_result.show(20, truncate=False)\n",
    "\n",
    "# Save results\n",
    "q4_result.coalesce(1).write.mode(\"overwrite\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"output/spark_results/q4_active_customers\")\n",
    "\n",
    "print(\"✅ Q4 completed and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5af84b",
   "metadata": {},
   "source": [
    "### Q5. Total Trade Amount by Day of Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "823f850b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Q5: Total Trade Amount per Day of Week (Highest to Lowest)\n",
      "================================================================================\n",
      "+--------+--------------------+\n",
      "|day_name|total_trade_amount  |\n",
      "+--------+--------------------+\n",
      "|2       |6.074148518912527E7 |\n",
      "|4       |5.929508948897399E7 |\n",
      "|1       |5.869949108159069E7 |\n",
      "|0       |5.809298904268309E7 |\n",
      "|3       |5.2834481894753695E7|\n",
      "+--------+--------------------+\n",
      "\n",
      "✅ Q5 completed and saved\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Q5: Total Trade Amount per Day of Week (Highest to Lowest)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "q5_result = df.groupBy(\"day_name\") \\\n",
    "    .agg(spark_sum(\"total_trade_amount\").alias(\"total_trade_amount\")) \\\n",
    "    .orderBy(desc(\"total_trade_amount\"))\n",
    "\n",
    "q5_result.show(truncate=False)\n",
    "\n",
    "# Save results\n",
    "q5_result.coalesce(1).write.mode(\"overwrite\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"output/spark_results/q5_trade_by_day\")\n",
    "\n",
    "print(\"✅ Q5 completed and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc6c538",
   "metadata": {},
   "source": [
    "---------------------\n",
    "## Register DataFrame for SQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac35a1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DataFrame registered as 'stocks' view for SQL queries\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"stocks\")\n",
    "print(\"✅ DataFrame registered as 'stocks' view for SQL queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa15b12b",
   "metadata": {},
   "source": [
    "### Q1. Top 5 Most Traded Stocks by Quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2510dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SQL Q1: Top 5 Most Traded Stock Tickers by Total Quantity\n",
      "================================================================================\n",
      "+------------+--------------+\n",
      "|stock_ticker|total_quantity|\n",
      "+------------+--------------+\n",
      "|5           |611667        |\n",
      "|11          |428057        |\n",
      "|8           |314915        |\n",
      "|17          |153811        |\n",
      "|12          |152604        |\n",
      "+------------+--------------+\n",
      "\n",
      "✅ SQL Q1 completed and saved\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SQL Q1: Top 5 Most Traded Stock Tickers by Total Quantity\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sql_query_1 = \"\"\"\n",
    "    SELECT \n",
    "        stock_ticker,\n",
    "        SUM(quantity) as total_quantity\n",
    "    FROM stocks\n",
    "    GROUP BY stock_ticker\n",
    "    ORDER BY total_quantity DESC\n",
    "    LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "sql_q1_result = spark.sql(sql_query_1)\n",
    "sql_q1_result.show(truncate=False)\n",
    "\n",
    "# Save results\n",
    "sql_q1_result.coalesce(1).write.mode(\"overwrite\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"output/spark_results/sql_q1_top_5_stocks\")\n",
    "\n",
    "print(\"✅ SQL Q1 completed and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cf510b",
   "metadata": {},
   "source": [
    "### Q2. Average Trade Amount by Account Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f4f65cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SQL Q2: Average Trade Amount by Customer Account Type\n",
      "================================================================================\n",
      "+---------------------+------------------+-----------------+\n",
      "|customer_account_type|avg_trade_amount  |transaction_count|\n",
      "+---------------------+------------------+-----------------+\n",
      "|1                    |29250.822437240735|9113             |\n",
      "|0                    |26043.733739066833|887              |\n",
      "+---------------------+------------------+-----------------+\n",
      "\n",
      "✅ SQL Q2 completed and saved\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SQL Q2: Average Trade Amount by Customer Account Type\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sql_query_2 = \"\"\"\n",
    "    SELECT \n",
    "        customer_account_type,\n",
    "        AVG(total_trade_amount) as avg_trade_amount,\n",
    "        COUNT(*) as transaction_count\n",
    "    FROM stocks\n",
    "    GROUP BY customer_account_type\n",
    "    ORDER BY avg_trade_amount DESC\n",
    "\"\"\"\n",
    "\n",
    "sql_q2_result = spark.sql(sql_query_2)\n",
    "sql_q2_result.show(truncate=False)\n",
    "\n",
    "# Save results\n",
    "sql_q2_result.coalesce(1).write.mode(\"overwrite\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"output/spark_results/sql_q2_avg_by_account\")\n",
    "\n",
    "print(\"✅ SQL Q2 completed and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9684a5",
   "metadata": {},
   "source": [
    "### Q3. Holiday vs Non-Holiday Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9f6a1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SQL Q3: Transactions During Holidays vs Non-Holidays\n",
      "================================================================================\n",
      "+-----------+-----------------+--------------------+\n",
      "|period_type|transaction_count|total_trade_amount  |\n",
      "+-----------+-----------------+--------------------+\n",
      "|Holiday    |180              |5249307.697105034   |\n",
      "|Non-Holiday|9820             |2.8441422900002223E8|\n",
      "+-----------+-----------------+--------------------+\n",
      "\n",
      "✅ SQL Q3 completed and saved\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SQL Q3: Transactions During Holidays vs Non-Holidays\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sql_query_3 = \"\"\"\n",
    "    SELECT \n",
    "        CASE \n",
    "            WHEN is_holiday = 1 THEN 'Holiday'\n",
    "            ELSE 'Non-Holiday'\n",
    "        END as period_type,\n",
    "        COUNT(*) as transaction_count,\n",
    "        SUM(total_trade_amount) as total_trade_amount\n",
    "    FROM stocks\n",
    "    GROUP BY is_holiday\n",
    "    ORDER BY is_holiday DESC\n",
    "\"\"\"\n",
    "\n",
    "sql_q3_result = spark.sql(sql_query_3)\n",
    "sql_q3_result.show(truncate=False)\n",
    "\n",
    "# Save results\n",
    "sql_q3_result.coalesce(1).write.mode(\"overwrite\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"output/spark_results/sql_q3_holiday_comparison\")\n",
    "\n",
    "print(\"✅ SQL Q3 completed and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6160bc85",
   "metadata": {},
   "source": [
    "### Q4. Sectors with Highest Weekend Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32c45bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SQL Q4: Stock Sectors with Highest Weekend Trading Volume\n",
      "================================================================================\n",
      "+------------+--------------------+--------------------+-------------------+\n",
      "|stock_sector|total_weekend_volume|weekend_transactions|total_weekend_value|\n",
      "+------------+--------------------+--------------------+-------------------+\n",
      "+------------+--------------------+--------------------+-------------------+\n",
      "\n",
      "✅ SQL Q4 completed and saved\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SQL Q4: Stock Sectors with Highest Weekend Trading Volume\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sql_query_4 = \"\"\"\n",
    "    SELECT \n",
    "        stock_sector,\n",
    "        SUM(quantity) as total_weekend_volume,\n",
    "        COUNT(*) as weekend_transactions,\n",
    "        SUM(total_trade_amount) as total_weekend_value\n",
    "    FROM stocks\n",
    "    WHERE is_weekend = 1\n",
    "    GROUP BY stock_sector\n",
    "    ORDER BY total_weekend_volume DESC\n",
    "\"\"\"\n",
    "\n",
    "sql_q4_result = spark.sql(sql_query_4)\n",
    "sql_q4_result.show(truncate=False)\n",
    "\n",
    "# Save results\n",
    "sql_q4_result.coalesce(1).write.mode(\"overwrite\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"output/spark_results/sql_q4_weekend_sectors\")\n",
    "\n",
    "print(\"✅ SQL Q4 completed and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d100ae61",
   "metadata": {},
   "source": [
    "### Q5. Buy vs Sell by Liquidity Tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4541d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SQL Q5: Total Buy vs Sell Amount by Stock Liquidity Tier\n",
      "================================================================================\n",
      "+--------------------+----------------+-----------------+--------------------+---------+----------+\n",
      "|stock_liquidity_tier|total_buy_amount|total_sell_amount|total_amount        |buy_count|sell_count|\n",
      "+--------------------+----------------+-----------------+--------------------+---------+----------+\n",
      "|High                |0.0             |0.0              |2.2561455653055984E8|0        |0         |\n",
      "|Mid                 |0.0             |0.0              |6.107445517901835E7 |0        |0         |\n",
      "|Low                 |0.0             |0.0              |2974524.9875485194  |0        |0         |\n",
      "+--------------------+----------------+-----------------+--------------------+---------+----------+\n",
      "\n",
      "✅ SQL Q5 completed and saved\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SQL Q5: Total Buy vs Sell Amount by Stock Liquidity Tier\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sql_query_5 = \"\"\"\n",
    "    SELECT \n",
    "        stock_liquidity_tier,\n",
    "        SUM(CASE WHEN transaction_type = 'BUY' THEN total_trade_amount ELSE 0 END) as total_buy_amount,\n",
    "        SUM(CASE WHEN transaction_type = 'SELL' THEN total_trade_amount ELSE 0 END) as total_sell_amount,\n",
    "        SUM(total_trade_amount) as total_amount,\n",
    "        COUNT(CASE WHEN transaction_type = 'BUY' THEN 1 END) as buy_count,\n",
    "        COUNT(CASE WHEN transaction_type = 'SELL' THEN 1 END) as sell_count\n",
    "    FROM stocks\n",
    "    GROUP BY stock_liquidity_tier\n",
    "    ORDER BY total_amount DESC\n",
    "\"\"\"\n",
    "\n",
    "sql_q5_result = spark.sql(sql_query_5)\n",
    "sql_q5_result.show(truncate=False)\n",
    "\n",
    "# Save results\n",
    "sql_q5_result.coalesce(1).write.mode(\"overwrite\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"output/spark_results/sql_q5_liquidity_analysis\")\n",
    "\n",
    "print(\"✅ SQL Q5 completed and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b95a6458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "✅ All 5 Spark DataFrame questions completed\n",
      "✅ All 5 Spark SQL questions completed\n",
      "✅ Results saved to output/spark_results/\n",
      "================================================================================\n",
      "\n",
      "✅ Spark session stopped\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"✅ All 5 Spark DataFrame questions completed\")\n",
    "print(\"✅ All 5 Spark SQL questions completed\")\n",
    "print(\"✅ Results saved to output/spark_results/\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "spark.stop()\n",
    "print(\"\\n✅ Spark session stopped\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
